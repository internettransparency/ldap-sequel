{
 "cells": [
  {
   "cell_type": "code",
   "id": "2b984f7f-b69d-4d76-979e-45ff4c8c083e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T16:37:41.279907Z",
     "start_time": "2024-03-02T16:37:40.850484Z"
    }
   },
   "source": [
    "%run ./spark-instance-gustavo.ipynb"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "File \u001B[0;32m/tmp/ipykernel_3101408/3192788801.py:3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtime\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m time\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SparkConf\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msql\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SparkSession\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'pyspark'"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mget_ipython\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_line_magic\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrun\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m./spark-instance-gustavo.ipynb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/srv/hdd-pool/tma-gustavo-2023/workspace/ldap-dependency-code/venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2480\u001B[0m, in \u001B[0;36mInteractiveShell.run_line_magic\u001B[0;34m(self, magic_name, line, _stack_depth)\u001B[0m\n\u001B[1;32m   2478\u001B[0m     kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlocal_ns\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_local_scope(stack_depth)\n\u001B[1;32m   2479\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuiltin_trap:\n\u001B[0;32m-> 2480\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2482\u001B[0m \u001B[38;5;66;03m# The code below prevents the output from being displayed\u001B[39;00m\n\u001B[1;32m   2483\u001B[0m \u001B[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001B[39;00m\n\u001B[1;32m   2484\u001B[0m \u001B[38;5;66;03m# when the last Python token in the expression is a ';'.\u001B[39;00m\n\u001B[1;32m   2485\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(fn, magic\u001B[38;5;241m.\u001B[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001B[38;5;28;01mFalse\u001B[39;00m):\n",
      "File \u001B[0;32m/srv/hdd-pool/tma-gustavo-2023/workspace/ldap-dependency-code/venv/lib/python3.12/site-packages/IPython/core/magics/execution.py:737\u001B[0m, in \u001B[0;36mExecutionMagics.run\u001B[0;34m(self, parameter_s, runner, file_finder)\u001B[0m\n\u001B[1;32m    735\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m preserve_keys(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshell\u001B[38;5;241m.\u001B[39muser_ns, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__file__\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m    736\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshell\u001B[38;5;241m.\u001B[39muser_ns[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__file__\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m filename\n\u001B[0;32m--> 737\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshell\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msafe_execfile_ipy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mraise_exceptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    738\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m    740\u001B[0m \u001B[38;5;66;03m# Control the response to exit() calls made by the script being run\u001B[39;00m\n",
      "File \u001B[0;32m/srv/hdd-pool/tma-gustavo-2023/workspace/ldap-dependency-code/venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3005\u001B[0m, in \u001B[0;36mInteractiveShell.safe_execfile_ipy\u001B[0;34m(self, fname, shell_futures, raise_exceptions)\u001B[0m\n\u001B[1;32m   3003\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrun_cell(cell, silent\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, shell_futures\u001B[38;5;241m=\u001B[39mshell_futures)\n\u001B[1;32m   3004\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m raise_exceptions:\n\u001B[0;32m-> 3005\u001B[0m     \u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraise_error\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3006\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m result\u001B[38;5;241m.\u001B[39msuccess:\n\u001B[1;32m   3007\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m/srv/hdd-pool/tma-gustavo-2023/workspace/ldap-dependency-code/venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:308\u001B[0m, in \u001B[0;36mExecutionResult.raise_error\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    306\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39merror_before_exec\n\u001B[1;32m    307\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39merror_in_exec \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 308\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39merror_in_exec\n",
      "    \u001B[0;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "File \u001B[0;32m/tmp/ipykernel_3101408/3192788801.py:3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtime\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m time\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SparkConf\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msql\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SparkSession\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'pyspark'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T16:47:43.931670Z",
     "start_time": "2024-03-02T16:47:43.926725Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"hi\")",
   "id": "747ac459e56e0a07",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "e5e4c992-e8ce-48b7-8e9c-70bb49d9fd67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T16:39:33.223317Z",
     "start_time": "2024-03-02T16:39:33.199421Z"
    }
   },
   "source": [
    "clean_spark()"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clean_spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mclean_spark\u001B[49m()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'clean_spark' is not defined"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "3ea1680a-f7d2-4fd3-9079-c666e0d57693",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T16:38:26.486181Z",
     "start_time": "2024-03-02T16:38:23.360260Z"
    }
   },
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.errors import *\n",
    "from pyspark.sql.types import TimestampType, StringType\n",
    "import pyspark.sql.functions as psf\n",
    "from pyspark.storagelevel import StorageLevel"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 6\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdatetime\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m datetime\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01merrors\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msql\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtypes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TimestampType, StringType\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msql\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctions\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpsf\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'pyspark'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "1a0616a3",
   "metadata": {},
   "source": [
    "def rfc9325_recommendation(cipher, tls_version, public_key_size) -> str:\n",
    "    # https://datatracker.ietf.org/doc/html/rfc9325#name-general-guidelines\n",
    "    # about cipher suites:\n",
    "    # https://utcc.utoronto.ca/~cks/space/blog/tech/SSLCipherNames\n",
    "\n",
    "    # \"SHALL\" and \"MUST\"\n",
    "    cipher_params = cipher.split(\"_\")\n",
    "    veredict = \"Y\"\n",
    "    must_not = [\"NULL\", \"RC4\"]\n",
    "    if any(item in must_not for item in cipher_params):\n",
    "        veredict = \"N\"\n",
    "\n",
    "    for param in cipher_params:\n",
    "        try:\n",
    "            key_size = int(param.rstrip(\"L\"))\n",
    "            if key_size < 128:  # should not; 112 is must not\n",
    "                veredict = \"N\"\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    if \"_DES40_\" in cipher:\n",
    "        veredict = \"N\"\n",
    "\n",
    "    # the \"SHOULD NOT\" also taken into account\n",
    "    should_not = [\"TLS_RSA_WITH_\",  # e.g. TLS_RSA_WITH_AES_128_CBC_SHA\n",
    "                  \"TLS_DH_\", \n",
    "                  \"TLS_ECDH_\"  # https://doi.org/10.1007/978-3-319-24174-6_21\n",
    "                 ]\n",
    "    if any(i in cipher for i in should_not):\n",
    "        veredict = \"N\"\n",
    "\n",
    "    if tls_version == \"TLSv1.2\": \n",
    "        recommended_v2 = [\"TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\",\n",
    "                          \"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\",\n",
    "                          \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256\",\n",
    "                          \"TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384\"\n",
    "                         ]\n",
    "        if cipher in recommended_v2:\n",
    "            veredict = \"Y\"\n",
    "\n",
    "        if \"TLS_DHE_\" in cipher:\n",
    "            veredict = \"N\"\n",
    "\n",
    "    # _CBC_ should not be used unless encrypt-then-mac is successfully negotiated\n",
    "    # encrypt_then_mac extension in client hello with extension_type=0x16 and extension_data=<empty>\n",
    "    # https://datatracker.ietf.org/doc/html/rfc7366\n",
    "\n",
    "    # use client hello to detect ECDSA that use NIST curve P-256 and X25519 rfc4492#section-5.1\n",
    "    # secp256r1 and x25519\n",
    "\n",
    "    # https://www.rfc-editor.org/rfc/rfc8446#section-9.1\n",
    "    recommended_v3 = [\"TLS_AES_128_GCM_SHA256\",\n",
    "                      \"TLS_AES_256_GCM_SHA384\",\n",
    "                      \"TLS_CHACHA20_POLY1305_SHA256\"\n",
    "                     ]\n",
    "    if tls_version == \"TLSv1.3\":\n",
    "        if cipher in recommended_v3:\n",
    "            veredict = \"Y\"\n",
    "\n",
    "    # TODO key_exchange_size has to be retrieved from the ConnectionState in the Goscanner\n",
    "    #if \"DHE\" in cipher and (key_exchange_size is None or key_exchange_size < 2048):\n",
    "    #    veredict = \"N\"\n",
    "    #if \"ECDH\" in cipher and (key_exchange_size is None or key_exchange_size < 224):\n",
    "    #    veredict = \"N\"\n",
    "\n",
    "    if \"TLS_RSA_WITH_\" not in cipher and \"RSA\" in cipher:\n",
    "        hash_algo = cipher.split(\"_\")[-1]\n",
    "        recommended_hash = [\"SHA256\", \"SHA384\", \"SHA512\"]\n",
    "        not_recommended_hash = [\"SHA1\", \"SHA\", \"MD5\"]\n",
    "        if hash_algo in recommended_hash:\n",
    "            veredict = \"Y\"\n",
    "        elif hash_algo in not_recommended_hash:\n",
    "            veredict = \"N\"\n",
    "\n",
    "        if public_key_size is None or public_key_size < 2048:\n",
    "            veredict = \"N\"\n",
    "\n",
    "    # if \"truncated_hmac\": veredict = \"N\"  # in the extended client hello\n",
    "    return veredict\n",
    "\n",
    "\n",
    "is_rfc9325_recommended_udf = psf.udf(rfc9325_recommendation, StringType())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5ab88c24",
   "metadata": {},
   "source": [
    "### Extracting Censys data"
   ]
  },
  {
   "cell_type": "code",
   "id": "7937d736",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T16:38:30.300828Z",
     "start_time": "2024-03-02T16:38:30.287240Z"
    }
   },
   "source": [
    "DATASET = \"universal-internet-dataset\"\n",
    "CENSYS_BASE_PATH_FMT = \"censys/dataset={dataset}/format=parquet\"\n",
    "CENSYS_PATH_FMT = os.path.join(CENSYS_BASE_PATH_FMT, \"year={year}/month={month:02d}/day={day:02d}\")\n",
    "\n",
    "# Censys snapshot of 2022-Nov\n",
    "timestamps = [\n",
    "    datetime(2022, 11, 1),\n",
    "    datetime(2022, 11, 8),\n",
    "    datetime(2022, 11, 15),\n",
    "    datetime(2022, 11, 22),\n",
    "    datetime(2022, 11, 29),\n",
    "]\n",
    "\n",
    "\n",
    "def load_censys_data(ts):\n",
    "    censys_base_path = CENSYS_PATH_FMT.format(dataset=DATASET, year=ts.year, month=ts.month, day=ts.day)\n",
    "    try:\n",
    "        censys_df = spark.read.option(\"basePath\", f\"../dataset/{censys_base_path}\").parquet(f\"../dataset/{censys_base_path}\")\n",
    "    except AnalysisException as e:\n",
    "        print(e)\n",
    "    return censys_df\n",
    "\n",
    "\n",
    "def filter_df_by_label(df, ts, label: str):\n",
    "    llabel = label.lower()\n",
    "    dns_filtered_df = df.select('*').filter(\n",
    "        (psf.expr(f\"exists(dns_names, x -> lower(x) like '%.{llabel}.%') or exists(dns_names, x -> lower(x) like '{llabel}.%')\")) | \n",
    "        (psf.expr(f\"exists(r_dns_names, x -> lower(x) like '%.{llabel}.%') or exists(r_dns_names, x -> lower(x) like '{llabel}.%')\"))\n",
    "    )\n",
    "    dns_filtered_df = dns_filtered_df.withColumn(\"filter_source\", psf.lit(\"dns_rdns\"))\n",
    "\n",
    "    ser_filtered_df = df.select('*').where((psf.array_contains(psf.col(\"service_names_list\"), label.upper())))\n",
    "    ser_filtered_df = ser_filtered_df.withColumn(\"filter_source\", psf.lit(\"service_name\"))\n",
    "\n",
    "    filtered_df = ser_filtered_df.unionByName(dns_filtered_df)\n",
    "    uniq_filtered_df = filtered_df.dropDuplicates([\"ipv4\"])\n",
    "    uniq_filtered_df = uniq_filtered_df.withColumn(\"date\", psf.lit(ts).cast(TimestampType()))\n",
    "\n",
    "    return uniq_filtered_df"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "a81b328f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T16:38:32.243090Z",
     "start_time": "2024-03-02T16:38:32.196987Z"
    }
   },
   "source": [
    "from ip_as_org import IPASnPrefix, ASOrg\n",
    "\n",
    "def ip_to_country(ip: str) -> str:\n",
    "    asn = ip_asn.get_asn_from_ip(ip)\n",
    "    return as_org.get_country_from_asn(asn)\n",
    "\n",
    "def ip_to_org(ip: str) -> str:\n",
    "    asn = ip_asn.get_asn_from_ip(ip)\n",
    "    return as_org.get_org_name_from_asn(asn)\n",
    "\n",
    "dataset_dir = \"../dataset/\""
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyasn'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mip_as_org\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m IPASnPrefix, ASOrg\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mip_to_country\u001B[39m(ip: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mstr\u001B[39m:\n\u001B[1;32m      4\u001B[0m     asn \u001B[38;5;241m=\u001B[39m ip_asn\u001B[38;5;241m.\u001B[39mget_asn_from_ip(ip)\n",
      "File \u001B[0;32m/srv/hdd-pool/tma-gustavo-2023/workspace/ldap-dependency-code/notebooks/ip_as_org.py:8\u001B[0m\n\u001B[1;32m      5\u001B[0m __author__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGustavo Luvizotto Cesar\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      6\u001B[0m __email__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mg.luvizottocesar@utwente.nl\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpyasn\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GetPyAsnDataset, GetAsOrgDataset\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'pyasn'"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "bdc52f52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T16:38:43.432777Z",
     "start_time": "2024-03-02T16:38:43.393058Z"
    }
   },
   "source": [
    "ip_to_country_udf = psf.udf(ip_to_country, StringType())\n",
    "ip_to_org_udf = psf.udf(ip_to_org, StringType())\n",
    "\n",
    "CENSYS_TS_DICT = {}\n",
    "for ts in timestamps:\n",
    "    print(ts)\n",
    "    censys_df = load_censys_data(ts)\n",
    "\n",
    "    select_df = censys_df.select(\"host_identifier.ipv4\",\n",
    "                                 censys_df.dns.names.alias(\"dns_names\"),\n",
    "                                 censys_df.dns.reverse_dns.names.alias(\"r_dns_names\"),\n",
    "                                 \"service_names_list\",\n",
    "                                 \"services.port\",\n",
    "                                 censys_df.services.tls.version_selected.alias(\"tls_version\"),\n",
    "                                 censys_df.services.tls.cipher_selected.alias(\"tls_cipher\"),\n",
    "                                 \"services.tls.certificates.leaf_data.pubkey_bit_size\",\n",
    "                                 censys_df.services.tls.certificates.leaf_data.signature.self_signed.alias(\"tls_signature_self_signed\"),\n",
    "                                 censys_df.services.tls.certificates.leaf_data.signature.signature_algorithm.alias(\"tls_signature_algorithm\"),\n",
    "                                 censys_df.services.tls.certificates.leaf_data.subject.common_name.alias(\"cert_cn\"),\n",
    "                                 censys_df.services.tls.certificates.leaf_data.issuer.common_name.alias(\"issuer_cn\")\n",
    "                                )\n",
    "\n",
    "    uniq_filtered_df = filter_df_by_label(select_df, \"ldap\")\n",
    "    when = ts.strftime(\"%Y%m%d\")\n",
    "    ip_asn = IPASnPrefix(when, dataset_dir)\n",
    "    as_org = ASOrg(when, dataset_dir)\n",
    "    uniq_filtered_df = uniq_filtered_df.withColumn(\"country\", ip_to_country_udf(psf.col(\"ipv4\")))\n",
    "    uniq_filtered_df = uniq_filtered_df.withColumn(\"org\", ip_to_org_udf(psf.col(\"ipv4\")))\n",
    "\n",
    "    CENSYS_TS_DICT[ts] = uniq_filtered_df\n",
    "print(\"-------\")"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'psf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m ip_to_country_udf \u001B[38;5;241m=\u001B[39m \u001B[43mpsf\u001B[49m\u001B[38;5;241m.\u001B[39mudf(ip_to_country, StringType())\n\u001B[1;32m      2\u001B[0m ip_to_org_udf \u001B[38;5;241m=\u001B[39m psf\u001B[38;5;241m.\u001B[39mudf(ip_to_org, StringType())\n\u001B[1;32m      4\u001B[0m CENSYS_TS_DICT \u001B[38;5;241m=\u001B[39m {}\n",
      "\u001B[0;31mNameError\u001B[0m: name 'psf' is not defined"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "966d6b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|              Fruits|  Numbers|\n",
      "+--------------------+---------+\n",
      "|[apple, banana, c...|[1, 2, 3]|\n",
      "|[mango, guava, pi...|[4, 5, 6]|\n",
      "+--------------------+---------+\n",
      "\n",
      "+---------+------+\n",
      "|    Fruit|Number|\n",
      "+---------+------+\n",
      "|    apple|     1|\n",
      "|   cherry|     3|\n",
      "|pineapple|     6|\n",
      "+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create data\n",
    "data = [\n",
    "    ([\"apple\", \"banana\", \"cherry\"], [1, 2, 3]),\n",
    "    ([\"mango\", \"guava\", \"pineapple\"], [4, 5, 6])\n",
    "]\n",
    "\n",
    "# Create columns list\n",
    "columns = [\"Fruits\", \"Numbers\"]\n",
    "\n",
    "# Create dataframe\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Display dataframe\n",
    "df.show()\n",
    "exploded_df = df.select(psf.explode_outer(psf.arrays_zip(df.Fruits, df.Numbers)).alias(\"exploded\"))\n",
    "exploded_df = exploded_df.select(psf.col(\"exploded.Fruits\").alias(\"Fruit\"), psf.col(\"exploded.Numbers\").alias(\"Number\"))\n",
    "\n",
    "exploded_df = exploded_df.filter(\n",
    "   (psf.col(\"Fruit\").like(\"%apple%\")) | (psf.col(\"Number\").like(\"%3%\"))\n",
    ")\n",
    "exploded_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815ada67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in CENSYS_TS_DICT.values():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
