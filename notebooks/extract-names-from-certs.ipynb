{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0905b97f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T09:16:21.223847Z",
     "start_time": "2024-03-25T09:16:21.217415Z"
    }
   },
   "outputs": [],
   "source": [
    "import tldextract\n",
    "import tld\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "from cryptography import x509\n",
    "from cryptography.hazmat.backends import default_backend\n",
    "from cryptography.hazmat.primitives import hashes\n",
    "\n",
    "import pyspark.sql.functions as psf\n",
    "import pyspark.sql.types as pst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a005aea0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T09:05:35.049472Z",
     "start_time": "2024-03-25T09:05:32.522314Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkConf created\n",
      "Started SparkSession\n",
      "Spark version 3.5.0\n"
     ]
    }
   ],
   "source": [
    "%run ./spark-instance-gustavo.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67cd40a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clean_spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mclean_spark\u001b[49m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clean_spark' is not defined"
     ]
    }
   ],
   "source": [
    "clean_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1c4977b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T09:35:37.477983Z",
     "start_time": "2024-03-25T09:35:37.453853Z"
    }
   },
   "outputs": [],
   "source": [
    "def eval_list_list_str(my_list):\n",
    "    try:\n",
    "        if isinstance(my_list, str):\n",
    "            return eval(my_list)\n",
    "        else:\n",
    "            return [[]]\n",
    "    except:\n",
    "        return [[]]\n",
    "\n",
    "\n",
    "eval_list_list_str_udf = psf.udf(eval_list_list_str, pst.ArrayType(pst.ArrayType(pst.StringType())))\n",
    "\n",
    "\n",
    "def eval_list(my_list):\n",
    "    try:\n",
    "        if isinstance(my_list, str):\n",
    "            return eval(my_list)\n",
    "        else:\n",
    "            return []\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "\n",
    "eval_udf = psf.udf(eval_list, pst.ArrayType(pst.IntegerType()))\n",
    "\n",
    "\n",
    "def load_hosts_data(port, ts):\n",
    "    hosts_base_path = HOSTS_PATH_FMT.format(port=port, year=ts.year, month=ts.month, day=ts.day)\n",
    "    hosts_df = spark.read.option(\"header\", \"true\") \\\n",
    "                         .option(\"lineSep\", \"\\n\") \\\n",
    "                         .option(\"quote\", \"\\\"\") \\\n",
    "                         .option(\"escape\", \"\\\"\") \\\n",
    "                         .option(\"inferSchema\", \"true\") \\\n",
    "                         .csv(f\"../dataset/{hosts_base_path}\")\n",
    "    return hosts_df\n",
    "\n",
    "\n",
    "def load_certs_data(port, ts):\n",
    "    certs_base_path = CERTS_PATH_FMT.format(port=port, year=ts.year, month=ts.month, day=ts.day)\n",
    "    certs_df = spark.read.option(\"header\", \"true\") \\\n",
    "                         .option(\"multiline\", \"true\") \\\n",
    "                         .option(\"wholeFile\", \"true\") \\\n",
    "                         .option(\"inferSchema\", \"true\") \\\n",
    "                         .csv(f\"../dataset/{certs_base_path}\")\n",
    "    return certs_df\n",
    "\n",
    "\n",
    "\n",
    "def load_ldap_data(port, ts):\n",
    "    ldap_base_path = LDAP_PATH_FMT.format(port=port, year=ts.year, month=ts.month, day=ts.day)\n",
    "    ldap_df = spark.read.option(\"header\", \"true\") \\\n",
    "                        .option(\"lineSep\", \"\\n\") \\\n",
    "                        .option(\"quote\", \"\\\"\") \\\n",
    "                        .option(\"escape\", \"\\\"\") \\\n",
    "                        .option(\"inferSchema\", \"true\") \\\n",
    "                        .csv(f\"../dataset/{ldap_base_path}\")\n",
    "    return ldap_df\n",
    "\n",
    "\n",
    "def load_ldapstarttls_data(port, ts):\n",
    "    starttls_base_path = STARTTLS_PATH_FMT.format(port=port, year=ts.year, month=ts.month, day=ts.day)\n",
    "    starttls_df = spark.read.option(\"header\", \"true\") \\\n",
    "                            .option(\"lineSep\", \"\\n\") \\\n",
    "                            .option(\"quote\", \"\\\"\") \\\n",
    "                            .option(\"escape\", \"\\\"\") \\\n",
    "                            .option(\"inferSchema\", \"true\") \\\n",
    "                            .csv(f\"../dataset/{starttls_base_path}\")\n",
    "    return starttls_df\n",
    "\n",
    "\n",
    "# port 636 scans occurs one day earlier than port 389\n",
    "PORT_SCANDATE_MAP = {\n",
    "    636: [\n",
    "        datetime(2024, 2, 20),\n",
    "        datetime(2024, 2, 27),\n",
    "        datetime(2024, 3, 5),\n",
    "        datetime(2024, 3, 12),\n",
    "        datetime(2024, 3, 19)\n",
    "    ],\n",
    "    389: [\n",
    "        datetime(2024, 2, 21),\n",
    "        datetime(2024, 2, 28),\n",
    "        datetime(2024, 3, 6),\n",
    "        datetime(2024, 3, 13),\n",
    "        datetime(2024, 3, 20)\n",
    "    ]\n",
    "}\n",
    "\n",
    "HOSTS_PATH_FMT = \"catrin/measurements/tool=goscanner/format=raw/port={port}/scan=tcp/result=hosts/year={year}/month={month:02d}/day={day:02d}\"\n",
    "CERTS_PATH_FMT = \"catrin/measurements/tool=goscanner/format=raw/port={port}/scan=tls/result=certs/year={year}/month={month:02d}/day={day:02d}\"\n",
    "LDAP_PATH_FMT = \"catrin/measurements/tool=goscanner/format=raw/port={port}/scan=ldap/result=ldap/year={year}/month={month:02d}/day={day:02d}\"\n",
    "STARTTLS_PATH_FMT = \"catrin/measurements/tool=goscanner/format=raw/port={port}/scan=starttls_ldap/result=starttls_ldap/year={year}/month={month:02d}/day={day:02d}\"\n",
    "\n",
    "goscanner_timestamps = []\n",
    "for dates in PORT_SCANDATE_MAP.values():\n",
    "    goscanner_timestamps.extend(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87d455cb84e513a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T09:17:59.952968Z",
     "start_time": "2024-03-25T09:17:59.936375Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Decoding X.509 certificates\n",
    "def get_x509(pem: str):\n",
    "    return x509.load_pem_x509_certificate(str.encode(pem), default_backend())\n",
    "\n",
    "\n",
    "def get_extensions(cert):\n",
    "    tls_key_exchange = []\n",
    "    san_list = []\n",
    "    try:\n",
    "        extensions = cert.extensions\n",
    "        for extension in extensions:\n",
    "            if isinstance(extension.value, x509.TLSFeature):\n",
    "                tls_key_exchange.append(extension.value.key_exchange)\n",
    "                continue\n",
    "            if isinstance(extension.value, x509.SubjectAlternativeName):\n",
    "                subject_alt_name = extension.value\n",
    "                san_list += [name for name in subject_alt_name.get_values_for_type(x509.DNSName)]\n",
    "                continue\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return tls_key_exchange, san_list\n",
    "\n",
    "\n",
    "def get_x509_fields(pem: str):\n",
    "    try:\n",
    "        cert = get_x509(pem)\n",
    "    except ValueError:\n",
    "        # the certificate contains bytes that cannot be interpreted. Probably invalid cert\n",
    "        # https://github.com/pyca/cryptography/issues/6804\n",
    "        print(pem)\n",
    "        return 4 * [None]  # CHANGE HERE IN CASE ADDITIONAL RETURN PARAMETER\n",
    "\n",
    "    _, san_list = get_extensions(cert)\n",
    "\n",
    "    public_key_size = None\n",
    "    try:\n",
    "        public_key_size = cert.public_key().key_size\n",
    "    except AttributeError:\n",
    "        #'cryptography.hazmat.bindings._rust.openssl.ed25519' object has no attribute 'key_size'\n",
    "        pass\n",
    "\n",
    "    cert_fp = cert.fingerprint(hashes.SHA256()).hex().upper()\n",
    "\n",
    "    return (cert.signature_algorithm_oid._name,\n",
    "            public_key_size,\n",
    "            san_list,\n",
    "            cert_fp,\n",
    "           )\n",
    "\n",
    "\n",
    "pem_decoded_schema = pst.StructType([pst.StructField(\"tls_signature_algorithm\", pst.StringType(), True),\n",
    "                                     pst.StructField(\"pubkey_bit_size\", pst.IntegerType(), True),\n",
    "                                     pst.StructField(\"leaf_data_names\", pst.ArrayType(pst.StringType()), True),  # SAN\n",
    "                                     pst.StructField(\"fingerprint\", pst.StringType(), True),\n",
    "                                    ])\n",
    "\n",
    "\n",
    "decode_cert_udf = psf.udf(get_x509_fields, pem_decoded_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aff1a23748ce655f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T15:30:54.945177Z",
     "start_time": "2024-03-25T15:30:36.896622Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636\n",
      "2024-02-20 00:00:00\n",
      "2024-02-27 00:00:00\n",
      "2024-03-05 00:00:00\n",
      "2024-03-12 00:00:00\n",
      "2024-03-19 00:00:00\n",
      "------------------\n",
      "389\n",
      "2024-02-21 00:00:00\n",
      "2024-02-28 00:00:00\n",
      "2024-03-06 00:00:00\n",
      "2024-03-13 00:00:00\n",
      "2024-03-20 00:00:00\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for port, ts_list in PORT_SCANDATE_MAP.items():\n",
    "    print(port)\n",
    "    for ts in ts_list:\n",
    "        print(ts)\n",
    "        hosts_df = load_hosts_data(port, ts)\n",
    "\n",
    "        hosts_df = hosts_df.withColumnRenamed(\"id\", \"host_id\")\n",
    "        hosts_df = hosts_df.withColumnRenamed(\"cert_id\", \"hosts_cert_id\")\n",
    "        hosts_df = hosts_df.select(\"host_id\", \"hosts_cert_id\")\n",
    "\n",
    "        certs_df = load_certs_data(port, ts)\n",
    "        certs_df = certs_df.withColumnRenamed(\"id\", \"cert_id\")\n",
    "        certs_df = certs_df.withColumn(\"decoded_cert\", decode_cert_udf(psf.col(\"cert\"))).drop(\"cert\", \"system_cert_store\").select(\"cert_id\", \"decoded_cert.*\")\n",
    "\n",
    "        ldap_df = None\n",
    "        if port == 636:\n",
    "            ldap_df = load_ldap_data(port, ts)\n",
    "        else:  # port 389\n",
    "            ldap_df = load_ldapstarttls_data(port, ts)\n",
    "\n",
    "        ldap_df = ldap_df.withColumnRenamed(\"id\", \"ldap_id\").select(\"ldap_id\", \"ldap_server\")\n",
    "\n",
    "        ldap_id_df = ldap_df.filter(psf.col(\"ldap_server\") == 1).select(\"ldap_id\")\n",
    "\n",
    "        ldap_hosts_df = hosts_df.join(ldap_id_df, ldap_id_df.ldap_id == hosts_df.host_id, \"inner\").filter(psf.col(\"ldap_id\").isNotNull()).drop(\"ldap_id\")\n",
    "\n",
    "        ldap_hosts_cert_df = ldap_hosts_df.join(certs_df, ldap_hosts_df.hosts_cert_id == certs_df.cert_id, \"inner\").drop(\"hosts_cert_id\", \"cert_id\")\n",
    "        \n",
    "        when = ts.strftime(\"%Y%m%d\")\n",
    "        ldap_hosts_cert_df = ldap_hosts_cert_df.withColumn(\"date\", psf.lit(when))\n",
    "\n",
    "        dfs.append(ldap_hosts_cert_df)\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98314c9da3d99eda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T08:55:53.390694Z",
     "start_time": "2024-03-26T08:55:53.281313Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "goscanner_df = dfs[0].unionByName(dfs[1])\n",
    "for i in range(2, len(dfs)):\n",
    "    goscanner_df = goscanner_df.unionByName(dfs[i])\n",
    "\n",
    "output = \"../dataset/processing/2024-goscanner-ldap-san\"\n",
    "goscanner_df.coalesce(1).pandas_api().to_parquet(output, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "78069fc0-73ca-4465-845a-a612502aff31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T09:09:08.514787Z",
     "start_time": "2024-03-26T09:09:07.941454Z"
    }
   },
   "outputs": [],
   "source": [
    "parquet_file = \"../dataset/catrin/ldap-dependency-2023Nov-goscanner.parquet\"  # November 2023\n",
    "#parquet_file = \"../dataset/catrin/2024-goscanner-ldap-san.parquet\"  # February-March 2024\n",
    "goscanner_df = spark.read.parquet(parquet_file)\n",
    "output = \"../dataset/processing/2023-Nov-leaf_data_names\"\n",
    "goscanner_df.select(psf.explode_outer(\"leaf_data_names\").alias(\"san\")).distinct().coalesce(1).pandas_api().to_csv(output, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "038f53b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T09:09:16.336856Z",
     "start_time": "2024-03-26T09:09:15.518012Z"
    }
   },
   "outputs": [],
   "source": [
    "def fld(domain):\n",
    "    if domain is None:\n",
    "        return None\n",
    "    domain = str(domain)\n",
    "    try:\n",
    "        tld.get_tld(domain, fail_silently=False, fix_protocol=True)\n",
    "        return tld.get_fld(domain, fail_silently=False, fix_protocol=True)\n",
    "    except tld.exceptions.TldBadUrl:\n",
    "        return None\n",
    "    except tld.exceptions.TldDomainNotFound:\n",
    "        return None\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_sld(domain):\n",
    "    if domain is None:\n",
    "        return None\n",
    "    domain = str(domain)\n",
    "    try:\n",
    "        return tldextract.extract(domain).registered_domain\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "c = glob(f\"{output}/*.csv\")\n",
    "san_pdf = pd.read_csv(c[0])\n",
    "san_pdf[\"fld\"] = san_pdf.san.apply(fld)\n",
    "san_pdf[\"sld\"] = san_pdf.san.apply(get_sld)\n",
    "\n",
    "valid_names_pdf = san_pdf[san_pdf[\"fld\"].notnull()]\n",
    "additional_names_pdf = pd.DataFrame(valid_names_pdf[\"sld\"].unique(), columns=[\"san\"])\n",
    "names_pdf = pd.concat([pd.DataFrame(valid_names_pdf[\"san\"], columns=[\"san\"]), additional_names_pdf], ignore_index=True).drop_duplicates(subset=[\"san\"])\n",
    "names_pdf = names_pdf[names_pdf[\"san\"] != \"\"].sort_values(\"san\", ascending=True)\n",
    "names_pdf.to_csv(\"../dataset/processing/san.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
