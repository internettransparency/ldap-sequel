{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "91a8fa60-b04d-4045-b0fd-1c454b66d30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkConf created\n",
      "Started SparkSession\n",
      "Spark version 3.3.1\n"
     ]
    }
   ],
   "source": [
    "%run ./spark-instance.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85cb6ff5-9188-4dc2-9d63-18bfe9f8690d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clean_spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mclean_spark\u001b[49m()  \u001b[38;5;66;03m# run by EOB\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clean_spark' is not defined"
     ]
    }
   ],
   "source": [
    "clean_spark()  # run by EOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d96619d6-3470-46dc-8e19-2c655c624c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import math\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from cryptography import x509\n",
    "from cryptography.hazmat.backends import default_backend\n",
    "from cryptography.hazmat.primitives import hashes\n",
    "\n",
    "\n",
    "import pyspark.sql.functions as psf\n",
    "import pyspark.sql.types as pst\n",
    "from pyspark.storagelevel import StorageLevel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b545297b-e9e0-41f2-9872-2fd761da8a63",
   "metadata": {},
   "source": [
    "### Extracting Censys data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ed24f69a-8cf2-4144-9bce-632e993bfb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"universal-internet-dataset\"\n",
    "CENSYS_BASE_PATH_FMT = \"censys/dataset={dataset}/format=parquet\"\n",
    "CENSYS_PATH_FMT = os.path.join(CENSYS_BASE_PATH_FMT, \"year={year}/month={month:02d}/day={day:02d}\")\n",
    "\n",
    "# Censys snapshot of 2022-Nov\n",
    "timestamps = [\n",
    "    datetime(2022, 11, 1),\n",
    "    datetime(2022, 11, 8),\n",
    "    datetime(2022, 11, 15),\n",
    "    datetime(2022, 11, 22),\n",
    "    datetime(2022, 11, 29),\n",
    "]\n",
    "\n",
    "\n",
    "def load_censys_data(ts):\n",
    "    censys_base_path = CENSYS_PATH_FMT.format(dataset=DATASET, year=ts.year, month=ts.month, day=ts.day)\n",
    "    try:\n",
    "        censys_df = spark.read.option(\"basePath\", f\"s3a://{censys_base_path}\").parquet(f\"s3a://{censys_base_path}\")\n",
    "    except AnalysisException as e:\n",
    "        print(e)\n",
    "    return censys_df\n",
    "\n",
    "\n",
    "def filter_df_by_label(df, ts, label: str):\n",
    "    llabel = label.lower()\n",
    "\n",
    "    ser_filtered_df = df.select('*').where((psf.array_contains(psf.col(\"service_names_list\"), label.upper())))\n",
    "    ser_filtered_df = ser_filtered_df.withColumn(\"filter_source\", psf.lit(\"service_name\"))\n",
    "\n",
    "    if False:\n",
    "        dns_filtered_df = df.select('*').filter(\n",
    "            (psf.expr(f\"exists(dns_names, x -> lower(x) like '%.{llabel}.%') or exists(dns_names, x -> lower(x) like '{llabel}.%')\")) | \n",
    "            (psf.expr(f\"exists(r_dns_names, x -> lower(x) like '%.{llabel}.%') or exists(r_dns_names, x -> lower(x) like '{llabel}.%')\"))\n",
    "        )\n",
    "        dns_filtered_df = dns_filtered_df.withColumn(\"filter_source\", psf.lit(\"dns_rdns\"))\n",
    "\n",
    "        filtered_df = ser_filtered_df.unionByName(dns_filtered_df)\n",
    "        uniq_filtered_df = filtered_df.dropDuplicates([\"ipv4\"])\n",
    "        uniq_filtered_df = uniq_filtered_df.withColumn(\"date\", psf.lit(ts).cast(pst.TimestampType()))\n",
    "\n",
    "    return ser_filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d45e4ed-c146-409b-a914-496dfab7f32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-01 00:00:00\n",
      "2022-11-08 00:00:00\n",
      "2022-11-15 00:00:00\n",
      "2022-11-22 00:00:00\n",
      "2022-11-29 00:00:00\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "CENSYS_TS_DICT = {}\n",
    "for ts in timestamps:\n",
    "    print(ts)\n",
    "    _censys_df = load_censys_data(ts)\n",
    "\n",
    "    select_df = _censys_df.select(\"host_identifier.ipv4\",\n",
    "                                 _censys_df.dns.names.alias(\"dns_names\"),\n",
    "                                 _censys_df.dns.reverse_dns.names.alias(\"r_dns_names\"),\n",
    "                                 \"service_names_list\",\n",
    "                                 \"services.port\",\n",
    "                                 _censys_df.services.tls.certificates.leaf_data.names.alias(\"leaf_data_names\"),\n",
    "                                 _censys_df.services.tls.version_selected.alias(\"tls_version\"),\n",
    "                                 _censys_df.services.tls.cipher_selected.alias(\"tls_cipher\"),\n",
    "                                 \"services.tls.certificates.leaf_data.pubkey_bit_size\",\n",
    "                                 _censys_df.services.tls.certificates.leaf_data.signature.self_signed.alias(\"tls_signature_self_signed\"),\n",
    "                                 _censys_df.services.tls.certificates.leaf_data.signature.signature_algorithm.alias(\"tls_signature_algorithm\"),\n",
    "                                 _censys_df.services.tls.certificates.leaf_data.subject.common_name.alias(\"cert_cn\"),\n",
    "                                 _censys_df.services.tls.certificates.leaf_data.issuer.common_name.alias(\"issuer_cn\")\n",
    "                                )\n",
    "\n",
    "    uniq_filtered_df = filter_df_by_label(select_df, ts, \"ldap\")\n",
    "\n",
    "    when = ts.strftime(\"%Y%m%d\")\n",
    "    uniq_filtered_df = uniq_filtered_df.withColumn(\"date\", psf.lit(ts).cast(pst.TimestampType()))\n",
    "\n",
    "    CENSYS_TS_DICT[ts] = uniq_filtered_df\n",
    "print(\"-------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fec5aa0d-2e21-47f8-ba54-3d3f764e7d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [df for df in CENSYS_TS_DICT.values()]\n",
    "\n",
    "censys_compact_df = dfs[0].unionByName(dfs[1])\n",
    "for i in range(2, len(dfs)):\n",
    "    censys_compact_df = censys_compact_df.unionByName(dfs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179d7a13-e069-4507-85f2-adb193846799",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = \"luvizottocesarg-tmp/ldap-dependency-censys_compact\"\n",
    "censys_compact_df.coalesce(1).write.parquet(f\"s3a://{output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea7256b-4c9c-4114-abe1-0a0180570aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for df in CENSYS_TS_DICT.values():\n",
    "    df2 = df.select(\"ipv4\", \"filter_source\", \"date\",\n",
    "                    psf.explode_outer(psf.arrays_zip(\n",
    "                                        df.dns_names.alias(\"dns_name\"),\n",
    "                                        df.r_dns_names.alias(\"r_dns_name\"),\n",
    "                                        df.leaf_data_names.alias(\"leaf_data_name\"),\n",
    "                                        df.service_names_list.alias(\"service_name\"),\n",
    "                                        df.port.alias(\"port\"),\n",
    "                                        df.tls_version,\n",
    "                                        df.tls_cipher,\n",
    "                                        df.pubkey_bit_size,\n",
    "                                        df.tls_signature_self_signed,\n",
    "                                        df.tls_signature_algorithm,\n",
    "                                        df.cert_cn,\n",
    "                                        df.issuer_cn)))\n",
    "    df2 = df2.select(\"ipv4\", \"filter_source\", \"date\",\n",
    "                     \"col.dns_name\", \"col.r_dns_name\", \"col.leaf_data_name\", \"col.service_name\", \"col.port\", \"col.tls_version\",\n",
    "                     \"col.tls_cipher\", \"col.pubkey_bit_size\", \"col.tls_signature_self_signed\",\n",
    "                     \"col.tls_signature_algorithm\", \"col.cert_cn\", \"col.issuer_cn\")\n",
    "\n",
    "    # look these examples. There are 2 LDAP services for the same IP, there is ldap0.acc.umu.se in the dns_names, dns_names with one element (first) mapps to the first service name (probably right?)\n",
    "    #df.filter((psf.col(\"ipv4\") == \"100.18.51.128\") | (psf.col(\"ipv4\") == \"100.37.175.222\") | (psf.col(\"ipv4\") == \"116.203.25.90\") | (psf.col(\"ipv4\") == \"130.239.18.143\")).select(\"ipv4\", \"filter_source\", \"dns_names\", \"service_names_list\", \"cert_cn\").show(truncate=False)\n",
    "    #df2.filter((psf.col(\"ipv4\") == \"100.18.51.128\") | (psf.col(\"ipv4\") == \"100.37.175.222\") | (psf.col(\"ipv4\") == \"116.203.25.90\") | (psf.col(\"ipv4\") == \"130.239.18.143\")).select(\"ipv4\", \"filter_source\", \"dns_name\", \"service_name\", \"cert_cn\").show(truncate=False)\n",
    "\n",
    "    if False:\n",
    "        df2_filtered = df2.filter((psf.col(\"dns_name\").like(\"%.ldap.%\")) | (psf.col(\"dns_name\").like(\"ldap.%\")) | (psf.col(\"r_dns_name\").like(\"%.ldap.%\")) | (psf.col(\"r_dns_name\").like(\"ldap.%\")) | (psf.col(\"service_name\") == \"LDAP\"))\n",
    "    df2_filtered = df2.filter(psf.col(\"service_name\") == \"LDAP\")\n",
    "\n",
    "    #display(df2_filtered.count())  # 94997\n",
    "    #display(df2_filtered.dropDuplicates([\"ipv4\"]).count())  # 74824\n",
    "    dfs.append(df2_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7fab85-5ea9-4eec-a81b-d96b4bda23d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "censys_df = dfs[0].unionByName(dfs[1])\n",
    "for i in range(2, len(dfs)):\n",
    "    censys_df = censys_df.unionByName(dfs[i])\n",
    "\n",
    "output = \"luvizottocesarg-tmp/ldap-dependency-censys\"\n",
    "censys_df.coalesce(1).write.parquet(f\"s3a://{output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd5b7f3-b24c-4343-b1ef-3903b724f4b8",
   "metadata": {},
   "source": [
    "### Extracting Goscanner data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c54d6948-e999-4496-8791-fc807b326515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hosts_data(port, ts):\n",
    "    hosts_base_path = HOSTS_PATH_FMT.format(port=port, year=ts.year, month=ts.month, day=ts.day)\n",
    "    hosts_df = spark.read.option(\"header\", \"true\") \\\n",
    "                         .option(\"lineSep\", \"\\n\") \\\n",
    "                         .option(\"quote\", \"\\\"\") \\\n",
    "                         .option(\"escape\", \"\\\"\") \\\n",
    "                         .option(\"inferSchema\", \"true\") \\\n",
    "                         .csv(f\"s3a://{hosts_base_path}\")\n",
    "    return hosts_df\n",
    "\n",
    "\n",
    "def load_certs_data(port, ts):\n",
    "    certs_base_path = CERTS_PATH_FMT.format(port=port, year=ts.year, month=ts.month, day=ts.day)\n",
    "    certs_df = spark.read.option(\"header\", \"true\") \\\n",
    "                         .option(\"multiline\", \"true\") \\\n",
    "                         .option(\"wholeFile\", \"true\") \\\n",
    "                         .option(\"inferSchema\", \"true\") \\\n",
    "                         .csv(f\"s3a://{certs_base_path}\")\n",
    "    return certs_df\n",
    "\n",
    "\n",
    "def load_tls_data(port, ts):\n",
    "    tls_base_path = TLS_PATH_FMT.format(port=port, year=ts.year, month=ts.month, day=ts.day)\n",
    "    tls_df = spark.read.option(\"header\", \"true\") \\\n",
    "                       .option(\"quote\", \"\\\"\") \\\n",
    "                       .option(\"escape\", \"\\\"\") \\\n",
    "                       .option(\"multiline\", \"true\") \\\n",
    "                       .option(\"wholeFile\", \"true\") \\\n",
    "                       .option(\"inferSchema\", \"true\") \\\n",
    "                       .csv(f\"s3a://{tls_base_path}\")\n",
    "    return tls_df\n",
    "\n",
    "\n",
    "def load_ldap_data(port, ts):\n",
    "    ldap_base_path = LDAP_PATH_FMT.format(port=port, year=ts.year, month=ts.month, day=ts.day)\n",
    "    ldap_df = spark.read.option(\"header\", \"true\") \\\n",
    "                        .option(\"lineSep\", \"\\n\") \\\n",
    "                        .option(\"quote\", \"\\\"\") \\\n",
    "                        .option(\"escape\", \"\\\"\") \\\n",
    "                        .option(\"inferSchema\", \"true\") \\\n",
    "                        .csv(f\"s3a://{ldap_base_path}\")\n",
    "    return ldap_df\n",
    "\n",
    "\n",
    "def load_ldapstarttls_data(port, ts):\n",
    "    starttls_base_path = STARTTLS_PATH_FMT.format(port=port, year=ts.year, month=ts.month, day=ts.day)\n",
    "    starttls_df = spark.read.option(\"header\", \"true\") \\\n",
    "                            .option(\"lineSep\", \"\\n\") \\\n",
    "                            .option(\"quote\", \"\\\"\") \\\n",
    "                            .option(\"escape\", \"\\\"\") \\\n",
    "                            .option(\"inferSchema\", \"true\") \\\n",
    "                            .csv(f\"s3a://{starttls_base_path}\")\n",
    "    return starttls_df\n",
    "\n",
    "\n",
    "def load_cert_validator(port, ts):\n",
    "    cert_validator_base_path = CERTVAL_PATH_FMT.format(port=port, year=ts.year, month=ts.month, day=ts.day)\n",
    "    df = spark.read.parquet(f\"s3a://{cert_validator_base_path}\")\n",
    "    return df\n",
    "\n",
    "def convert_ldap_attributes(df):\n",
    "    df = df.withColumn(\"asd\", eval_list_list_str_udf(psf.col(\"attribute_names\")))\n",
    "    df = df.drop(\"attribute_names\")\n",
    "    df = df.withColumnRenamed(\"asd\", \"attribute_names\")\n",
    "    df = df.withColumn(\"qwe\", eval_list_list_list_str_udf(psf.col(\"attribute_values_list\")))\n",
    "    df = df.drop(\"attribute_values_list\")\n",
    "    df = df.withColumnRenamed(\"qwe\", \"attribute_values_list\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def flatten_ldap_metadata(df):\n",
    "    df = df.select(\"id\", \"ip\", \"port\", \"result_code\", \"error_data\", \"matched_dns\",\n",
    "                                    psf.explode_outer(psf.arrays_zip(\n",
    "                                                      df.attribute_names,\n",
    "                                                      df.attribute_values_list)))\n",
    "    df = df.select(\"id\", \"ip\", \"port\", \"result_code\", \"error_data\", \"matched_dns\", \"col.attribute_names\", \"col.attribute_values_list\")\n",
    "    df = df.select(\"id\", \"ip\", \"port\", \"result_code\", \"error_data\", \"matched_dns\",\n",
    "                                    psf.explode_outer(psf.arrays_zip(\n",
    "                                                      df.attribute_names,\n",
    "                                                      df.attribute_values_list)))\n",
    "    df = df.select(\"id\", \"ip\", \"port\", \"result_code\", \"error_data\", \"matched_dns\", \"col.attribute_names\", \"col.attribute_values_list\")\n",
    "    df = df.withColumnRenamed(\"attribute_names\", \"attribute_name\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def flat_ldap_attr_values(df):\n",
    "    # good for vendorName filters for example\n",
    "    df = df.select(\"id\", \"ip\", \"port\", \"result_code\", \"error_data\", \"matched_dns\", \"attribute_name\", psf.explode_outer(df.attribute_values_list))\n",
    "    df = df.withColumnRenamed(\"col\", \"attribute_value\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_ldap_root_dse(port, ts):\n",
    "    root_dse_base_path = ROOT_DSE_PATH_FMT.format(port=port, year=ts.year, month=ts.month, day=ts.day)\n",
    "    df = spark.read.option(\"header\", \"true\") \\\n",
    "                   .option(\"multiline\", \"true\") \\\n",
    "                   .option(\"wholeFile\", \"true\") \\\n",
    "                   .option(\"inferSchema\", \"true\") \\\n",
    "                   .csv(f\"../dataset/{root_dse_base_path}\")\n",
    "\n",
    "    df = convert_ldap_attributes(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_ldap_schema(port, ts):\n",
    "    schema_base_path = SCHEMA_PATH_FMT.format(port=port, year=ts.year, month=ts.month, day=ts.day)\n",
    "    df = spark.read.option(\"header\", \"true\") \\\n",
    "                   .option(\"multiline\", \"true\") \\\n",
    "                   .option(\"wholeFile\", \"true\") \\\n",
    "                   .option(\"inferSchema\", \"true\") \\\n",
    "                   .csv(f\"../dataset/{schema_base_path}\")\n",
    "\n",
    "    df = convert_ldap_attributes(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "def convert_output_df(df):\n",
    "    df = df.select(\"id\", \"generic_error\", psf.explode(\"root_stores\").alias(\"store_name\", \"result\"))\n",
    "    df = df.select(\"id\", \"generic_error\", \"store_name\", \"result.*\")\n",
    "    df = df.withColumn(\"vc\", eval_list_list_str_udf(psf.col(\"valid_chains\")))\n",
    "    df = df.drop(\"valid_chains\")\n",
    "    df = df.withColumnRenamed(\"vc\", \"valid_chains\")\n",
    "    return df\n",
    "\n",
    "\n",
    "len_udf = psf.udf(lambda chain: [len(x) for x in chain], pst.ArrayType(pst.IntegerType()))\n",
    "\n",
    "\n",
    "def chain_len(df):\n",
    "    df = df.withColumn(\"chain_len\", len_udf(psf.col(\"valid_chains\")))\n",
    "    df.select(\"chain_len\").groupBy(psf.col(\"chain_len\")).count().show()\n",
    "    return df\n",
    "\n",
    "\n",
    "def peer_certs_len(peer_certs_str):\n",
    "    peer_certs = eval_list(peer_certs_str)\n",
    "    return len(peer_certs)\n",
    "\n",
    "\n",
    "peer_certs_len_udf = psf.udf(peer_certs_len, pst.IntegerType())\n",
    "\n",
    "def eval_list_list_list_str(my_list):\n",
    "    try:\n",
    "        if isinstance(my_list, str):\n",
    "            return eval(my_list)\n",
    "        else:\n",
    "            return [[[]]]\n",
    "    except:\n",
    "        return [[[]]]\n",
    "\n",
    "\n",
    "eval_list_list_list_str_udf = psf.udf(eval_list_list_list_str, pst.ArrayType(pst.ArrayType(pst.ArrayType(pst.StringType()))))\n",
    "\n",
    "\n",
    "def eval_list_list_str(my_list):\n",
    "    try:\n",
    "        if isinstance(my_list, str):\n",
    "            return eval(my_list)\n",
    "        else:\n",
    "            return [[]]\n",
    "    except:\n",
    "        return [[]]\n",
    "\n",
    "\n",
    "eval_list_list_str_udf = psf.udf(eval_list_list_str, pst.ArrayType(pst.ArrayType(pst.StringType())))\n",
    "\n",
    "\n",
    "def eval_list(my_list):\n",
    "    try:\n",
    "        if isinstance(my_list, str):\n",
    "            return eval(my_list)\n",
    "        else:\n",
    "            return []\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "\n",
    "eval_udf = psf.udf(eval_list, pst.ArrayType(pst.IntegerType()))\n",
    "\n",
    "\n",
    "SHORT1 = \"Signed by unknown authority\"\n",
    "SHORT2 = \"Expired/Not yet valid\"\n",
    "SHORT3 = \"Not authorized to sign other certificates\"\n",
    "SHORT4 = \"Too many intermediate certificates\"\n",
    "SHORT5 = \"Unhandled critical extension\"\n",
    "SHORT6 = \"Other errors\"\n",
    "SHORT7 = \"Self-signed\"\n",
    "SHORT8 = \"Valid chain\"\n",
    "SHORT9 = \"Invalid signature\"  # under SHORT1\n",
    "\n",
    "\n",
    "short_error_name_map = {\n",
    "    'x509: certificate signed by unknown authority': SHORT1,\n",
    "    'x509: certificate signed by unknown authority - With possible explanation': SHORT1,\n",
    "    'x509: certificate has expired or is not yet valid': SHORT2,\n",
    "    'x509: certificate is not authorized to sign other certificates': SHORT3,\n",
    "    'x509: too many intermediates for path length constraint': SHORT4,\n",
    "    'x509: unhandled critical extension': SHORT5,\n",
    "    'x509: certificate signed by unknown authority (possibly because of \"x509: invalid signature': SHORT9,\n",
    "    '': SHORT8\n",
    "}\n",
    "\n",
    "\n",
    "def error_str(error_list, skid, akid, peer_certs_len):\n",
    "    # test that all elements are empty\n",
    "    if all(not element for element in error_list):\n",
    "        return SHORT8\n",
    "\n",
    "    # get the first non-empty error\n",
    "    for error_data in error_list:\n",
    "        if error_data != \"\":\n",
    "            break\n",
    "\n",
    "    parsed_error = ':'.join(error_data.split(\":\")[:3])\n",
    "    if \"certificate signed by unknown authority\" in parsed_error:\n",
    "        #if peer_certs_len == 1:\n",
    "        if skid == \"\" or akid == \"\":\n",
    "            if peer_certs_len == 1:\n",
    "                return SHORT7\n",
    "        elif skid == akid:\n",
    "            return SHORT7\n",
    "\n",
    "    error = short_error_name_map.get(parsed_error, None)\n",
    "    if error is None:\n",
    "        parsed_error = ':'.join(error_data.split(\":\")[:2])\n",
    "        return short_error_name_map[parsed_error]\n",
    "    return error\n",
    "\n",
    "\n",
    "error_str_udf = psf.udf(error_str, pst.StringType())\n",
    "\n",
    "\n",
    "def error_str2(error_list, peer_certs_len):\n",
    "    # test that all elements are empty\n",
    "    if all(not element for element in error_list):\n",
    "        return SHORT8\n",
    "\n",
    "    # get the first non-empty error\n",
    "    for error_data in error_list:\n",
    "        if error_data != \"\":\n",
    "            break\n",
    "\n",
    "    parsed_error = ':'.join(error_data.split(\":\")[:3])\n",
    "    if \"certificate signed by unknown authority\" in parsed_error:\n",
    "        if peer_certs_len == 1:\n",
    "            return SHORT7\n",
    "\n",
    "    error = short_error_name_map.get(parsed_error, None)\n",
    "    if error is None:\n",
    "        parsed_error = ':'.join(error_data.split(\":\")[:2])\n",
    "        return short_error_name_map[parsed_error]\n",
    "    return error\n",
    "\n",
    "\n",
    "error_str2_udf = psf.udf(error_str2, pst.StringType())\n",
    "\n",
    "\n",
    "# port 636 scans occurs one day earlier than port 389\n",
    "PORT_SCANDATE_MAP = {\n",
    "    636: [\n",
    "        datetime(2023, 11, 7),\n",
    "        datetime(2023, 11, 14),\n",
    "        datetime(2023, 11, 21),\n",
    "        datetime(2023, 11, 28)\n",
    "    ],\n",
    "    389: [\n",
    "        #datetime(2023, 11, 1),  # does not have a 636 pair\n",
    "        datetime(2023, 11, 8),\n",
    "        datetime(2023, 11, 15),\n",
    "        datetime(2023, 11, 22),\n",
    "        datetime(2023, 11, 29)\n",
    "    ]\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "PORT_SCANDATE_MAP = {\n",
    "    636: [datetime(2024, 4, 23)],\n",
    "    389: [datetime(2024, 4, 24)],\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "PORT_SCANDATE_MAP = {\n",
    "    636: [\n",
    "        datetime(2024, 2, 20),\n",
    "        datetime(2024, 2, 27),\n",
    "        datetime(2024, 3, 5),\n",
    "        datetime(2024, 3, 12),\n",
    "        datetime(2024, 3, 19)\n",
    "    ],\n",
    "    389: [\n",
    "        datetime(2024, 2, 21),\n",
    "        datetime(2024, 2, 28),\n",
    "        datetime(2024, 3, 6),\n",
    "        datetime(2024, 3, 13),\n",
    "        datetime(2024, 3, 20)\n",
    "    ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "HOSTS_PATH_FMT = \"catrin/measurements/tool=goscanner/format=raw/port={port}/scan=tcp/result=hosts/year={year}/month={month:02d}/day={day:02d}\"\n",
    "CERTS_PATH_FMT = \"catrin/measurements/tool=goscanner/format=raw/port={port}/scan=tls/result=certs/year={year}/month={month:02d}/day={day:02d}\"\n",
    "TLS_PATH_FMT = \"catrin/measurements/tool=goscanner/format=raw/port={port}/scan=tls/result=tls_verbose/year={year}/month={month:02d}/day={day:02d}\"\n",
    "LDAP_PATH_FMT = \"catrin/measurements/tool=goscanner/format=raw/port={port}/scan=ldap/result=ldap/year={year}/month={month:02d}/day={day:02d}\"\n",
    "STARTTLS_PATH_FMT = \"catrin/measurements/tool=goscanner/format=raw/port={port}/scan=starttls_ldap/result=starttls_ldap/year={year}/month={month:02d}/day={day:02d}\"\n",
    "CERTVAL_PATH_FMT = \"catrin/data_processing/tool=cert-validator/format=parquet/port={port}/year={year}/month={month:02d}/day={day:02d}\"\n",
    "SCHEMA_PATH_FMT = \"catrin/measurements/tool=goscanner/format=raw/port={port}/scan=ldap_crawl/result=ldap_schema/year={year}/month={month:02d}/day={day:02d}\"\n",
    "ROOT_DSE_PATH_FMT = \"catrin/measurements/tool=goscanner/format=raw/port={port}/scan=ldap_crawl/result=ldap_root_dse/year={year}/month={month:02d}/day={day:02d}\"\n",
    "\n",
    "\n",
    "goscanner_timestamps = []\n",
    "for dates in PORT_SCANDATE_MAP.values():\n",
    "    goscanner_timestamps.extend(dates)\n",
    "\n",
    "\n",
    "tls_version_str_dict = {\n",
    "    int(\"0x0301\", 16): \"TLSv1.0\",\n",
    "    int(\"0x0302\", 16): \"TLSv1.1\",\n",
    "    int(\"0x0303\", 16): \"TLSv1.2\",\n",
    "    int(\"0x0304\", 16): \"TLSv1.3\",\n",
    "    int(\"0x0300\", 16): \"SSLv3\"\n",
    "}\n",
    "\n",
    "\n",
    "def tls_version_to_string(version_number: int):\n",
    "    return tls_version_str_dict.get(version_number, str(version_number))\n",
    "\n",
    "\n",
    "tls_version_udf = psf.udf(tls_version_to_string, pst.StringType())\n",
    "\n",
    "\n",
    "def convert_cipher(x):\n",
    "    try:\n",
    "        parts = [int(part, 16) for part in x.split(\",\")]\n",
    "    except ValueError:\n",
    "        # to cover reserved values like 0x00,0x1C-1D\n",
    "        return None\n",
    "    cipher = parts[0] << 8\n",
    "    cipher |= parts[1]\n",
    "    return hex(cipher)[2:]\n",
    "\n",
    "\n",
    "# https://www.iana.org/assignments/tls-parameters/tls-parameters.xhtml#tls-parameters-4\n",
    "tls_parameters_pdf = pd.read_csv(\"tls-parameters-4.csv\")\n",
    "tls_parameters_pdf[\"Cipher\"] = tls_parameters_pdf[\"Value\"].apply(convert_cipher)\n",
    "tls_parameters_pdf[\"DTLS-OK\"] = tls_parameters_pdf[\"DTLS-OK\"].apply(lambda x: str(x))\n",
    "tls_parameters_pdf[\"Recommended\"] = tls_parameters_pdf[\"Recommended\"].apply(lambda x: str(x))\n",
    "tls_parameters_pdf[\"Reference\"] = tls_parameters_pdf[\"Reference\"].apply(lambda x: str(x))\n",
    "tls_parameter_dict = tls_parameters_pdf[[\"Cipher\", \"Description\"]].set_index(\"Cipher\").to_dict()[\"Description\"]\n",
    "\n",
    "\n",
    "def cipher_to_description(cipher):\n",
    "    return tls_parameter_dict.get(cipher, \"Unknown\")\n",
    "\n",
    "\n",
    "cipher_to_description_udf = psf.udf(cipher_to_description, pst.StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "38ba23ac-a916-4526-ab00-6b7ccc1e3731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoding X.509 certificates\n",
    "def get_x509(pem: str):\n",
    "    return x509.load_pem_x509_certificate(str.encode(pem), default_backend())\n",
    "\n",
    "\n",
    "def get_extensions(cert):\n",
    "    tls_key_exchange = []\n",
    "    san_list = []\n",
    "    try:\n",
    "        extensions = cert.extensions\n",
    "        for extension in extensions:\n",
    "            if isinstance(extension.value, x509.TLSFeature):\n",
    "                tls_key_exchange.append(extension.value.key_exchange)\n",
    "                continue\n",
    "            if isinstance(extension.value, x509.SubjectAlternativeName):\n",
    "                subject_alt_name = extension.value\n",
    "                san_list += [name for name in subject_alt_name.get_values_for_type(x509.DNSName)]\n",
    "                continue\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return tls_key_exchange, san_list\n",
    "\n",
    "\n",
    "def get_x509_fields(pem: str):\n",
    "    try:\n",
    "        cert = get_x509(pem)\n",
    "    except ValueError:\n",
    "        # the certificate contains bytes that cannot be interpreted. Probably invalid cert\n",
    "        # https://github.com/pyca/cryptography/issues/6804\n",
    "        print(pem)\n",
    "        return 11 * [None]  # CHANGE HERE IN CASE ADDITIONAL RETURN PARAMETER\n",
    "\n",
    "    _, san_list = get_extensions(cert)\n",
    "    \n",
    "    subject_rdns = []\n",
    "    issuer_rdns = []\n",
    "    try:\n",
    "        issuer_rdns = [rdn.rfc4514_string() for rdn in cert.issuer.rdns]\n",
    "        subject_rdns = [rdn.rfc4514_string() for rdn in cert.subject.rdns]\n",
    "    except ValueError:\n",
    "        # the certificate contains bytes that cannot be interpreted. Probably invalid cert\n",
    "        # https://github.com/pyca/cryptography/issues/6804\n",
    "        pass\n",
    "\n",
    "    not_valid_after = None\n",
    "    try:\n",
    "        if cert.not_valid_after > datetime.min:\n",
    "            not_valid_after = cert.not_valid_after\n",
    "    except ValueError:\n",
    "        # ValueError: year 0 is out of range\n",
    "        pass\n",
    "    not_valid_before = None\n",
    "    try:\n",
    "        if cert.not_valid_before > datetime.min:\n",
    "            not_valid_before = cert.not_valid_before\n",
    "    except ValueError:\n",
    "        # ValueError: year 0 is out of range\n",
    "        pass\n",
    "\n",
    "    public_key_size = None\n",
    "    try:\n",
    "        public_key_size = cert.public_key().key_size\n",
    "    except AttributeError:\n",
    "        #'cryptography.hazmat.bindings._rust.openssl.ed25519' object has no attribute 'key_size'\n",
    "        pass\n",
    "\n",
    "    cert_fp = cert.fingerprint(hashes.SHA256()).hex().upper()\n",
    "\n",
    "    skid = \"\"\n",
    "    try:\n",
    "        skid = cert.extensions.get_extension_for_oid(x509.oid.ExtensionOID.SUBJECT_KEY_IDENTIFIER).value.digest.hex().upper()\n",
    "    except:\n",
    "        # x509.ExtensionNotFound\n",
    "        # Parse error\n",
    "        pass\n",
    "    \n",
    "    akid = \"\"\n",
    "    try:\n",
    "        akid = cert.extensions.get_extension_for_oid(x509.oid.ExtensionOID.AUTHORITY_KEY_IDENTIFIER).value.key_identifier.hex().upper()\n",
    "    except:\n",
    "        # x509.ExtensionNotFound\n",
    "        # Parse error\n",
    "        pass\n",
    "    \n",
    "    return (cert.signature_algorithm_oid._name,\n",
    "            public_key_size,\n",
    "            san_list,\n",
    "            cert_fp,\n",
    "            skid,\n",
    "            akid,\n",
    "            subject_rdns,\n",
    "            issuer_rdns,\n",
    "            cert.version.name,\n",
    "            not_valid_after,\n",
    "            not_valid_before,\n",
    "           )\n",
    "\n",
    "\n",
    "pem_decoded_schema = pst.StructType([pst.StructField(\"tls_signature_algorithm\", pst.StringType(), True),\n",
    "                                     pst.StructField(\"pubkey_bit_size\", pst.IntegerType(), True),\n",
    "                                     pst.StructField(\"leaf_data_names\", pst.ArrayType(pst.StringType()), True),  # SAN\n",
    "                                     pst.StructField(\"fingerprint\", pst.StringType(), True),\n",
    "                                     pst.StructField(\"subject_key_identifier\", pst.StringType(), True),\n",
    "                                     pst.StructField(\"authority_key_identifier\", pst.StringType(), True),\n",
    "                                     pst.StructField(\"subject_rdns\", pst.ArrayType(pst.StringType()), True),\n",
    "                                     pst.StructField(\"issuer_rdns\", pst.ArrayType(pst.StringType()), True),\n",
    "                                     pst.StructField(\"version\", pst.StringType(), True),\n",
    "                                     pst.StructField(\"not_valid_after\", pst.TimestampType(), True),\n",
    "                                     pst.StructField(\"not_valid_before\", pst.TimestampType(), True),\n",
    "                                    ])\n",
    "\n",
    "\n",
    "decode_cert_udf = psf.udf(get_x509_fields, pem_decoded_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8a59dc4b-f1b3-4956-95b1-5813943f5141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636\n",
      "2024-04-16 00:00:00\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "Path does not exist: s3a://catrin/data_processing/tool=cert-validator/format=parquet/port=636/year=2024/month=04/day=16",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m hosts_df \u001b[38;5;241m=\u001b[39m hosts_df\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhost_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mport\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mipv4\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprotocol\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcipher\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhosts_cert_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpeer_certificates\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m hosts_df \u001b[38;5;241m=\u001b[39m hosts_df\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpeer_certs_len\u001b[39m\u001b[38;5;124m\"\u001b[39m, peer_certs_len_udf(psf\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpeer_certificates\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpeer_certificates\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m certval_df \u001b[38;5;241m=\u001b[39m convert_output_df(\u001b[43mload_cert_validator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mts\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     15\u001b[0m certval_df \u001b[38;5;241m=\u001b[39m certval_df\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparsed_root_store_error\u001b[39m\u001b[38;5;124m\"\u001b[39m, parse_error_udf(psf\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot_store_error\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[1;32m     16\u001b[0m g_certval_df \u001b[38;5;241m=\u001b[39m certval_df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m     17\u001b[0m                         \u001b[38;5;241m.\u001b[39magg(psf\u001b[38;5;241m.\u001b[39mcollect_set(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore_name\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore_name_list\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     18\u001b[0m                             psf\u001b[38;5;241m.\u001b[39mcollect_list(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_valid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid_list\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     19\u001b[0m                             psf\u001b[38;5;241m.\u001b[39mcollect_list(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparsed_root_store_error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot_store_error_list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m                             )\n",
      "Cell \u001b[0;32mIn[64], line 84\u001b[0m, in \u001b[0;36mload_cert_validator\u001b[0;34m(port, ts)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_cert_validator\u001b[39m(port, ts):\n\u001b[1;32m     83\u001b[0m     cert_validator_base_path \u001b[38;5;241m=\u001b[39m CERTVAL_PATH_FMT\u001b[38;5;241m.\u001b[39mformat(port\u001b[38;5;241m=\u001b[39mport, year\u001b[38;5;241m=\u001b[39mts\u001b[38;5;241m.\u001b[39myear, month\u001b[38;5;241m=\u001b[39mts\u001b[38;5;241m.\u001b[39mmonth, day\u001b[38;5;241m=\u001b[39mts\u001b[38;5;241m.\u001b[39mday)\n\u001b[0;32m---> 84\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ms3a://\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcert_validator_base_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/readwriter.py:364\u001b[0m, in \u001b[0;36mDataFrameReader.parquet\u001b[0;34m(self, *paths, **options)\u001b[0m\n\u001b[1;32m    353\u001b[0m int96RebaseMode \u001b[38;5;241m=\u001b[39m options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint96RebaseMode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(\n\u001b[1;32m    355\u001b[0m     mergeSchema\u001b[38;5;241m=\u001b[39mmergeSchema,\n\u001b[1;32m    356\u001b[0m     pathGlobFilter\u001b[38;5;241m=\u001b[39mpathGlobFilter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m     int96RebaseMode\u001b[38;5;241m=\u001b[39mint96RebaseMode,\n\u001b[1;32m    362\u001b[0m )\n\u001b[0;32m--> 364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_seq\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    192\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Path does not exist: s3a://catrin/data_processing/tool=cert-validator/format=parquet/port=636/year=2024/month=04/day=16"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for port, ts_list in PORT_SCANDATE_MAP.items():\n",
    "    print(port)\n",
    "    for ts in ts_list:\n",
    "        print(ts)\n",
    "        hosts_df = load_hosts_data(port, ts)\n",
    "\n",
    "        hosts_df = hosts_df.withColumnRenamed(\"id\", \"host_id\")\n",
    "        hosts_df = hosts_df.withColumnRenamed(\"ip\", \"ipv4\")\n",
    "        hosts_df = hosts_df.withColumnRenamed(\"cert_id\", \"hosts_cert_id\")\n",
    "        hosts_df = hosts_df.select(\"host_id\", \"port\", \"ipv4\", \"protocol\", \"cipher\", \"hosts_cert_id\", \"peer_certificates\")\n",
    "        hosts_df = hosts_df.withColumn(\"peer_certs_len\", peer_certs_len_udf(psf.col(\"peer_certificates\"))).drop(\"peer_certificates\")\n",
    "\n",
    "        certval_df = convert_output_df(load_cert_validator(port, ts))\n",
    "        certval_df = certval_df.withColumn(\"parsed_root_store_error\", parse_error_udf(psf.col(\"root_store_error\")))\n",
    "        g_certval_df = certval_df.groupby(\"id\") \\\n",
    "                                .agg(psf.collect_set(\"store_name\").alias(\"store_name_list\"),\n",
    "                                    psf.collect_list(\"is_valid\").alias(\"valid_list\"),\n",
    "                                    psf.collect_list(\"parsed_root_store_error\").alias(\"root_store_error_list\")\n",
    "                                    )\n",
    "        g_certval_df = g_certval_df.withColumnRenamed(\"id\", \"certval_id\")\n",
    "\n",
    "        certs_df = load_certs_data(port, ts)\n",
    "        certs_df = certs_df.withColumnRenamed(\"id\", \"cert_id\")\n",
    "        certs_df = certs_df.withColumn(\"decoded_cert\", decode_cert_udf(psf.col(\"cert\"))).drop(\"cert\", \"system_cert_store\").select(\"cert_id\", \"decoded_cert.*\")\n",
    "\n",
    "        ldap_df = None\n",
    "        if port == 636:\n",
    "            ldap_df = load_ldap_data(port, ts)\n",
    "        else:  # port 389\n",
    "            ldap_df = load_ldapstarttls_data(port, ts)\n",
    "\n",
    "        ldap_df = ldap_df.withColumnRenamed(\"id\", \"ldap_id\").select(\"ldap_id\", \"ldap_server\")\n",
    "\n",
    "        ldap_id_df = ldap_df.filter(psf.col(\"ldap_server\") == 1).select(\"ldap_id\")\n",
    "\n",
    "        ldap_hosts_df = hosts_df.join(ldap_id_df, ldap_id_df.ldap_id == hosts_df.host_id, \"inner\").filter(psf.col(\"ldap_id\").isNotNull()).drop(\"ldap_id\")\n",
    "\n",
    "        ldap_hosts_cert_df = ldap_hosts_df.join(certs_df, ldap_hosts_df.hosts_cert_id == certs_df.cert_id, \"inner\").drop(\"hosts_cert_id\", \"cert_id\")\n",
    "\n",
    "        ldap_hosts_cert_val_df = ldap_hosts_cert_df.join(g_certval_df, ldap_hosts_cert_df.host_id == g_certval_df.certval_id, \"inner\").drop(\"certval_id\")\n",
    "\n",
    "\n",
    "        ldap_hosts_cert_val_df = ldap_hosts_cert_val_df.withColumn(\"tls_version\", tls_version_udf(psf.col(\"protocol\"))).drop(\"protocol\")\n",
    "        ldap_hosts_cert_val_df = ldap_hosts_cert_val_df.withColumn(\"tls_cipher\", cipher_to_description_udf(psf.col(\"cipher\"))).drop(\"cipher\")\n",
    "        \n",
    "        when = ts.strftime(\"%Y%m%d\")\n",
    "        ldap_hosts_cert_val_df = ldap_hosts_cert_val_df.withColumn(\"date\", psf.lit(when))\n",
    "\n",
    "        dfs.append(ldap_hosts_cert_val_df)\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ab66a0-59ff-4104-94ff-a496d89c55bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "goscanner_df = dfs[0].unionByName(dfs[1])\n",
    "for i in range(2, len(dfs)):\n",
    "    goscanner_df = goscanner_df.unionByName(dfs[i])\n",
    "\n",
    "output = \"luvizottocesarg-tmp/2023-ldap-dependency-goscanner\"\n",
    "output = \"luvizottocesarg-tmp/2024-04-ldap-dependency-goscanner\"\n",
    "goscanner_df.coalesce(1).write.parquet(f\"s3a://{output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b829c4-ceca-4b1f-a6b1-5657a9ba8084",
   "metadata": {},
   "source": [
    "### Retrieve SAN from goscanner dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b22e9700-6b24-4ed1-8055-844546116803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636\n",
      "2024-02-20 00:00:00\n",
      "2024-02-27 00:00:00\n",
      "2024-03-05 00:00:00\n",
      "2024-03-12 00:00:00\n",
      "2024-03-19 00:00:00\n",
      "------------------\n",
      "389\n",
      "2024-02-21 00:00:00\n",
      "2024-02-28 00:00:00\n",
      "2024-03-06 00:00:00\n",
      "2024-03-13 00:00:00\n",
      "2024-03-20 00:00:00\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for port, ts_list in PORT_SCANDATE_MAP.items():\n",
    "    print(port)\n",
    "    for ts in ts_list:\n",
    "        print(ts)\n",
    "        hosts_df = load_hosts_data(port, ts)\n",
    "\n",
    "        hosts_df = hosts_df.withColumnRenamed(\"id\", \"host_id\")\n",
    "        hosts_df = hosts_df.withColumnRenamed(\"cert_id\", \"hosts_cert_id\")\n",
    "        hosts_df = hosts_df.select(\"host_id\", \"hosts_cert_id\")\n",
    "\n",
    "        certs_df = load_certs_data(port, ts)\n",
    "        certs_df = certs_df.withColumnRenamed(\"id\", \"cert_id\")\n",
    "        certs_df = certs_df.withColumn(\"decoded_cert\", decode_cert_udf(psf.col(\"cert\"))).drop(\"cert\", \"system_cert_store\").select(\"cert_id\", \"decoded_cert.*\")\n",
    "\n",
    "        ldap_df = None\n",
    "        if port == 636:\n",
    "            ldap_df = load_ldap_data(port, ts)\n",
    "        else:  # port 389\n",
    "            ldap_df = load_ldapstarttls_data(port, ts)\n",
    "\n",
    "        ldap_df = ldap_df.withColumnRenamed(\"id\", \"ldap_id\").select(\"ldap_id\", \"ldap_server\")\n",
    "\n",
    "        ldap_id_df = ldap_df.filter(psf.col(\"ldap_server\") == 1).select(\"ldap_id\")\n",
    "\n",
    "        ldap_hosts_df = hosts_df.join(ldap_id_df, ldap_id_df.ldap_id == hosts_df.host_id, \"inner\").filter(psf.col(\"ldap_id\").isNotNull()).drop(\"ldap_id\")\n",
    "\n",
    "        ldap_hosts_cert_df = ldap_hosts_df.join(certs_df, ldap_hosts_df.hosts_cert_id == certs_df.cert_id, \"inner\").drop(\"hosts_cert_id\", \"cert_id\")\n",
    "        \n",
    "        when = ts.strftime(\"%Y%m%d\")\n",
    "        ldap_hosts_cert_df = ldap_hosts_cert_df.withColumn(\"date\", psf.lit(when))\n",
    "\n",
    "        dfs.append(ldap_hosts_cert_df)\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2f883a1-49e8-4116-94c2-1238968a813e",
   "metadata": {},
   "outputs": [],
   "source": [
    "goscanner_df = dfs[0].unionByName(dfs[1])\n",
    "for i in range(2, len(dfs)):\n",
    "    goscanner_df = goscanner_df.unionByName(dfs[i])\n",
    "\n",
    "output = \"luvizottocesarg-tmp/2024-goscanner-ldap-san\"\n",
    "goscanner_df.coalesce(1).write.parquet(f\"s3a://{output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0996f5f-65a3-4f7c-b755-ec498a138eeb",
   "metadata": {},
   "source": [
    "### Cert validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "08bb632f-2516-453b-b22b-51209c168633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636\n",
      "2023-11-07 00:00:00\n",
      "2023-11-14 00:00:00\n",
      "2023-11-21 00:00:00\n",
      "2023-11-28 00:00:00\n",
      "389\n",
      "2023-11-01 00:00:00\n",
      "2023-11-08 00:00:00\n",
      "2023-11-15 00:00:00\n",
      "2023-11-22 00:00:00\n",
      "2023-11-29 00:00:00\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for port, timestamps in PORT_SCANDATE_MAP.items():\n",
    "    print(port)\n",
    "    for ts in timestamps:\n",
    "        print(ts)\n",
    "        _hosts_df = load_hosts_data(port, ts)\n",
    "\n",
    "        _hosts_df = _hosts_df.withColumnRenamed(\"id\", \"host_id\")\n",
    "        _hosts_df = _hosts_df.withColumnRenamed(\"ip\", \"ipv4\")\n",
    "        _hosts_df = _hosts_df.withColumnRenamed(\"cert_id\", \"hosts_cert_id\")  # to use skid and akid\n",
    "        _hosts_df = _hosts_df.select(\"host_id\", \"ipv4\", \"port\", \"peer_certificates\", \"hosts_cert_id\")\n",
    "        _hosts_df = _hosts_df.withColumn(\"peer_certs_len\", peer_certs_len_udf(psf.col(\"peer_certificates\"))).drop(\"peer_certificates\")\n",
    "\n",
    "        _certs_df = load_certs_data(port, ts)\n",
    "        _certs_df = _certs_df.withColumnRenamed(\"id\", \"cert_id\")\n",
    "        _certs_df = _certs_df.withColumn(\"decoded_cert\", decode_cert_udf(psf.col(\"cert\"))).drop(\"cert\", \"system_cert_store\").select(\"cert_id\", \"decoded_cert.*\")\n",
    "        \n",
    "        _cert_val_df = load_cert_validator(port, ts)\n",
    "        _cert_val_df = convert_output_df(_cert_val_df)\n",
    "\n",
    "        _cert_val_df = _cert_val_df.groupby(\"id\") \\\n",
    "                                     .agg(psf.collect_set(\"store_name\").alias(\"store_name_list\"),\n",
    "                                          psf.collect_list(\"is_valid\").alias(\"valid_list\"),\n",
    "                                          psf.collect_list(\"root_store_error\").alias(\"root_store_error_list\")\n",
    "                                         )\n",
    "\n",
    "        _cert_val_df = _cert_val_df.withColumn(\"date\", psf.lit(ts).cast(pst.TimestampType()))\n",
    "\n",
    "        _cert_val_hosts_df = _cert_val_df.join(_hosts_df, _cert_val_df.id == _hosts_df.host_id, \"inner\").drop(\"host_id\")\n",
    "        joined_df = _cert_val_hosts_df.join(_certs_df, _cert_val_hosts_df.hosts_cert_id == _certs_df.cert_id, \"inner\").drop(\"hosts_cert_id\", \"cert_id\")\n",
    "        joined_df = joined_df.withColumn(\"validation_error\", error_str_udf(psf.col(\"root_store_error_list\"),\n",
    "                                                                           psf.col(\"subject_key_identifier\"),\n",
    "                                                                           psf.col(\"authority_key_identifier\"),\n",
    "                                                                           psf.col(\"peer_certs_len\")\n",
    "                                                                          ))\n",
    "        #joined_df = _cert_val_hosts_df\n",
    "        #joined_df = joined_df.withColumn(\"validation_error\", error_str2_udf(psf.col(\"root_store_error_list\"),\n",
    "        #                                                                   psf.col(\"peer_certs_len\")\n",
    "        #                                                                  ))\n",
    "        dfs.append(joined_df)\n",
    "\n",
    "\n",
    "cert_val_df = dfs[0].unionByName(dfs[1])\n",
    "for i in range(2, len(dfs)):\n",
    "    cert_val_df = cert_val_df.unionByName(dfs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d7ee9df3-0d3f-47d0-8b1d-f0daafb30303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------+------+\n",
      "|validation_error                         |count |\n",
      "+-----------------------------------------+------+\n",
      "|Self-signed                              |77748 |\n",
      "|Signed by unknown authority              |378235|\n",
      "|Valid chain                              |486062|\n",
      "|Unhandled critical extension             |63    |\n",
      "|Expired/Not yet valid                    |95705 |\n",
      "|Not authorized to sign other certificates|177   |\n",
      "|Invalid signature                        |319   |\n",
      "|Too many intermediate certificates       |4     |\n",
      "+-----------------------------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cert_val_df.persist()\n",
    "cert_val_df.groupBy(\"validation_error\").count().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "abf26f10-6194-4708-a242-bcdd9bc2c9d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: int, store_name_list: array<string>, valid_list: array<boolean>, root_store_error_list: array<string>, date: timestamp, ipv4: string, port: int, peer_certs_len: int, tls_signature_algorithm: string, pubkey_bit_size: int, leaf_data_names: array<string>, fingerprint: string, subject_key_identifier: string, authority_key_identifier: string, subject_rdns: array<string>, issuer_rdns: array<string>, version: string, not_valid_after: timestamp, not_valid_before: timestamp, validation_error: string]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = \"luvizottocesarg-tmp/2023-Nov-cert-validator-processing\"\n",
    "cert_val_df.coalesce(1).write.parquet(f\"s3a://{output}\")\n",
    "cert_val_df.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8d8ad0-046a-4b6b-b308-49eca745883d",
   "metadata": {},
   "source": [
    "### Extracting hosts and ldap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624cb5db-cf6b-4e4f-bd0f-891086fef563",
   "metadata": {},
   "source": [
    "without preprocess... Let the user do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "307667a1-6c7b-46b3-be83-1d8dd9f62360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636\n",
      "2023-11-07 00:00:00\n",
      "2023-11-14 00:00:00\n",
      "2023-11-21 00:00:00\n",
      "2023-11-28 00:00:00\n",
      "389\n",
      "2023-11-08 00:00:00\n",
      "2023-11-15 00:00:00\n",
      "2023-11-22 00:00:00\n",
      "2023-11-29 00:00:00\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for port, timestamps in PORT_SCANDATE_MAP.items():\n",
    "    print(port)\n",
    "    for ts in timestamps:\n",
    "        print(ts)\n",
    "        _hosts_df = load_hosts_data(port, ts)\n",
    "\n",
    "        _hosts_df = _hosts_df.withColumnRenamed(\"id\", \"host_id\")\n",
    "        _hosts_df = _hosts_df.withColumnRenamed(\"ip\", \"ipv4\")\n",
    "        _hosts_df = _hosts_df.select(\"host_id\", \"ipv4\", \"port\")\n",
    "\n",
    "        _ldap_df = None\n",
    "        if port == 636:\n",
    "            _ldap_df = load_ldap_data(port, ts)\n",
    "        else:  # port 389\n",
    "            _ldap_df = load_ldapstarttls_data(port, ts)\n",
    "\n",
    "        _ldap_df = _ldap_df.withColumnRenamed(\"id\", \"ldap_id\").select(\"ldap_id\", \"ldap_server\")\n",
    "        _ldap_id_df = _ldap_df.filter(psf.col(\"ldap_server\") == 1).select(\"ldap_id\")\n",
    "\n",
    "        joined_df = _hosts_df.join(_ldap_id_df, _ldap_id_df.ldap_id == _hosts_df.host_id, \"inner\").filter(psf.col(\"ldap_id\").isNotNull()).drop(\"ldap_id\")\n",
    "\n",
    "        joined_df = joined_df.withColumn(\"date\", psf.lit(ts).cast(pst.TimestampType()))\n",
    "        dfs.append(joined_df)\n",
    "\n",
    "\n",
    "all_df = dfs[0].unionByName(dfs[1])\n",
    "for i in range(2, len(dfs)):\n",
    "    all_df = all_df.unionByName(dfs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5a29bcd8-d839-462e-85c7-ea5e7e1434aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = f\"luvizottocesarg-tmp/{ts.year}-{ts.month:02d}-hosts_ldap-nopreprocess\"\n",
    "all_df.coalesce(1).write.parquet(f\"s3a://{output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b0dc0f-83e2-4283-b051-32f89c228fa8",
   "metadata": {},
   "source": [
    "### Extracting hosts, certs, cert_val, tls_verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "02d38ab0-ca31-417e-a366-98a3f9c4e750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636\n",
      "2023-11-07 00:00:00\n",
      "ldap 36965\n",
      "ldap join host 36965\n",
      "ldap join host join certval 36905\n",
      "2023-11-14 00:00:00\n",
      "ldap 37012\n",
      "ldap join host 37012\n",
      "ldap join host join certval 36950\n",
      "2023-11-21 00:00:00\n",
      "ldap 37081\n",
      "ldap join host 37081\n",
      "ldap join host join certval 36996\n",
      "2023-11-28 00:00:00\n",
      "ldap 36973\n",
      "ldap join host 36973\n",
      "ldap join host join certval 36889\n",
      "389\n",
      "2023-11-08 00:00:00\n",
      "ldap 78472\n",
      "ldap join host 78472\n",
      "ldap join host join certval 38139\n",
      "2023-11-15 00:00:00\n",
      "ldap 78005\n",
      "ldap join host 78005\n",
      "ldap join host join certval 38043\n",
      "2023-11-22 00:00:00\n",
      "ldap 78203\n",
      "ldap join host 78203\n",
      "ldap join host join certval 38029\n",
      "2023-11-29 00:00:00\n",
      "ldap 78243\n",
      "ldap join host 78243\n",
      "ldap join host join certval 37983\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for port, timestamps in PORT_SCANDATE_MAP.items():\n",
    "    print(port)\n",
    "    for ts in timestamps:\n",
    "        print(ts)\n",
    "        _hosts_df = load_hosts_data(port, ts)\n",
    "\n",
    "        _hosts_df = _hosts_df.withColumnRenamed(\"id\", \"host_id\")\n",
    "        _hosts_df = _hosts_df.withColumnRenamed(\"ip\", \"ipv4\")\n",
    "        _hosts_df = _hosts_df.withColumnRenamed(\"cert_id\", \"hosts_cert_id\")\n",
    "        _hosts_df = _hosts_df.select(\"host_id\", \"ipv4\", \"port\", \"protocol\", \"cipher\", \"peer_certificates\", \"hosts_cert_id\")\n",
    "\n",
    "        _certs_df = load_certs_data(port, ts)\n",
    "        _certs_df = _certs_df.withColumnRenamed(\"id\", \"cert_id\")\n",
    "        _certs_df = _certs_df.select(\"cert_id\", \"cert\")\n",
    "        \n",
    "        _tls_df = load_tls_data(port, ts)\n",
    "        _tls_df = _tls_df.withColumnRenamed(\"id\", \"tls_id\")\n",
    "        _tls_df = _tls_df.withColumnRenamed(\"fingerprint\", \"tls_fingerprint\")\n",
    "        _tls_df = _tls_df.select(\"tls_id\", \"tls_fingerprint\")\n",
    "\n",
    "        _cert_val_df = load_cert_validator(port, ts)\n",
    "        _cert_val_df = convert_output_df(_cert_val_df)\n",
    "\n",
    "        _cert_val_df = _cert_val_df.groupby(\n",
    "            \"id\"\n",
    "        ).agg(\n",
    "            psf.collect_set(\"store_name\").alias(\"store_name_list\"),\n",
    "            psf.collect_list(\"is_valid\").alias(\"valid_list\"),\n",
    "            psf.collect_list(\"root_store_error\").alias(\"root_store_error_list\")\n",
    "        )\n",
    "        \n",
    "        _ldap_df = None\n",
    "        if port == 636:\n",
    "            _ldap_df = load_ldap_data(port, ts)\n",
    "        else:  # port 389\n",
    "            _ldap_df = load_ldapstarttls_data(port, ts)\n",
    "\n",
    "        _ldap_df = _ldap_df.withColumnRenamed(\"id\", \"ldap_id\").select(\"ldap_id\", \"ldap_server\")\n",
    "        _ldap_id_df = _ldap_df.filter(psf.col(\"ldap_server\") == 1).select(\"ldap_id\")\n",
    "        print(\"ldap\", _ldap_id_df.count())\n",
    "        _ldap_hosts_df = _hosts_df.join(_ldap_id_df, _ldap_id_df.ldap_id == _hosts_df.host_id, \"inner\").filter(psf.col(\"ldap_id\").isNotNull()).drop(\"ldap_id\")\n",
    "        print(\"ldap join host\", _ldap_hosts_df.count())\n",
    "        _cert_val_ldap_hosts_df = _ldap_hosts_df.join(_cert_val_df, _ldap_hosts_df.host_id == _cert_val_df.id, \"inner\").drop(\"host_id\")\n",
    "        print(\"ldap join host join certval\", _cert_val_ldap_hosts_df.count())\n",
    "        _cert_val_ldap_hosts_certs_df = _cert_val_ldap_hosts_df.join(_certs_df, _cert_val_ldap_hosts_df.hosts_cert_id == _certs_df.cert_id, \"inner\").drop(\"hosts_cert_id\", \"cert_id\")\n",
    "        \n",
    "        joined_df = _cert_val_ldap_hosts_certs_df.join(_tls_df, _tls_df.tls_id == _cert_val_ldap_hosts_certs_df.id, \"inner\").drop(\"tls_id\")\n",
    "        \n",
    "        joined_df = joined_df.withColumn(\"date\", psf.lit(ts).cast(pst.TimestampType()))\n",
    "        dfs.append(joined_df)\n",
    "\n",
    "\n",
    "all_df = dfs[0].unionByName(dfs[1])\n",
    "for i in range(2, len(dfs)):\n",
    "    all_df = all_df.unionByName(dfs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c05ad7ba-fe50-4a39-9878-3e576a09840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = f\"luvizottocesarg-tmp/{ts.year}-{ts.month:02d}-hosts_certs_certval_tls-nopreprocess\"\n",
    "all_df.coalesce(1).write.parquet(f\"s3a://{output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c13a7bf-3b17-47f0-9802-7c077b8beb2d",
   "metadata": {},
   "source": [
    "### Extract peer certificates from LDAP servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f6b4b1d8-7b44-4867-a6f6-8e6f94ba8c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636\n",
      "2023-11-07 00:00:00\n",
      "2023-11-14 00:00:00\n",
      "2023-11-21 00:00:00\n",
      "2023-11-28 00:00:00\n",
      "389\n",
      "2023-11-08 00:00:00\n",
      "2023-11-15 00:00:00\n",
      "2023-11-22 00:00:00\n",
      "2023-11-29 00:00:00\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for port, timestamps in PORT_SCANDATE_MAP.items():\n",
    "    print(port)\n",
    "    for ts in timestamps:\n",
    "        print(ts)\n",
    "        _hosts_df = load_hosts_data(port, ts)\n",
    "\n",
    "        _hosts_df = _hosts_df.withColumnRenamed(\"id\", \"host_id\")\n",
    "        _hosts_df = _hosts_df.withColumnRenamed(\"ip\", \"ipv4\")\n",
    "        _hosts_df = _hosts_df.select(\"host_id\", \"ipv4\", \"port\", \"peer_certificates\")\n",
    "\n",
    "        _certs_df = load_certs_data(port, ts)\n",
    "        _certs_df = _certs_df.withColumnRenamed(\"id\", \"cert_id\")\n",
    "        _certs_df = _certs_df.select(\"cert_id\", \"cert\")\n",
    "\n",
    "        _cert_val_df = load_cert_validator(port, ts)\n",
    "        _cert_val_df = convert_output_df(_cert_val_df)\n",
    "\n",
    "        _cert_val_df = _cert_val_df.groupby(\n",
    "            \"id\"\n",
    "        ).agg(\n",
    "            psf.collect_set(\"store_name\").alias(\"store_name_list\"),\n",
    "            psf.collect_list(\"is_valid\").alias(\"valid_list\"),\n",
    "            psf.collect_list(\"root_store_error\").alias(\"root_store_error_list\")\n",
    "        )\n",
    "\n",
    "        _ldap_df = None\n",
    "        if port == 636:\n",
    "            _ldap_df = load_ldap_data(port, ts)\n",
    "        else:  # port 389\n",
    "            _ldap_df = load_ldapstarttls_data(port, ts)\n",
    "\n",
    "        _ldap_df = _ldap_df.withColumnRenamed(\"id\", \"ldap_id\").select(\"ldap_id\", \"ldap_server\")\n",
    "        _ldap_id_df = _ldap_df.filter(psf.col(\"ldap_server\") == 1).select(\"ldap_id\")\n",
    "\n",
    "        _hosts_df = _hosts_df.withColumn(\"a\", eval_udf(psf.col(\"peer_certificates\"))).drop(\"peer_certificates\").withColumnRenamed(\"a\", \"peer_certificates\")\n",
    "        _hosts_df = _hosts_df.select(\"host_id\", \"ipv4\", \"port\", psf.explode_outer(_hosts_df.peer_certificates).alias(\"peer_certificate\"))\n",
    "\n",
    "        _ldap_hosts_df = _hosts_df.join(_ldap_id_df, _ldap_id_df.ldap_id == _hosts_df.host_id, \"inner\").filter(psf.col(\"ldap_id\").isNotNull()).drop(\"ldap_id\")\n",
    "\n",
    "        _cert_val_ldap_hosts_df = _ldap_hosts_df.join(_cert_val_df, _ldap_hosts_df.host_id == _cert_val_df.id, \"inner\").drop(\"host_id\")\n",
    "\n",
    "        joined_df = _cert_val_ldap_hosts_df.join(_certs_df, _cert_val_ldap_hosts_df.peer_certificate == _certs_df.cert_id, \"inner\").drop(\"cert_id\")\n",
    "\n",
    "        joined_df = joined_df.withColumn(\"date\", psf.lit(ts).cast(pst.TimestampType()))\n",
    "\n",
    "        joined_df = joined_df.groupBy(\"id\", \"ipv4\", \"port\", \"store_name_list\", \"valid_list\", \"root_store_error_list\", \"date\"\n",
    "                                     ).agg(psf.collect_list(\"peer_certificate\").alias(\"peer_certificates\"),\n",
    "                                           psf.collect_list(\"cert\").alias(\"certificates\")\n",
    "                                          )\n",
    "        dfs.append(joined_df)\n",
    "\n",
    "all_df = dfs[0].unionByName(dfs[1])\n",
    "for i in range(2, len(dfs)):\n",
    "    all_df = all_df.unionByName(dfs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e2375245-32a1-4ddd-b6b4-a343b2c705a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = f\"luvizottocesarg-tmp/{ts.year}-{ts.month:02d}-hosts_peercerts_certval-nopreprocess\"\n",
    "all_df.coalesce(1).write.parquet(f\"s3a://{output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c4bf5d-cb0d-457c-b52b-c5a22c6f7f52",
   "metadata": {},
   "source": [
    "### Extracting crawl and schema with TLS and X509 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a65a8a4-6cfa-48ea-b951-ee2e62fb5047",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for port, timestamps in PORT_SCANDATE_MAP.items():\n",
    "    print(port)\n",
    "    for ts in timestamps:\n",
    "        print(ts)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
